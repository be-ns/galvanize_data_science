### Week 3 of the Data Science Immersive:  
#### Linear Models 
![regression regression regression](https://media.giphy.com/media/OnL8XGDvzcaha/giphy.gif)

##### Brief forward  
  * Well - three weeks into the official immersive and I'll go ahead and say it.  
  I should have dome more pre-course studying for math.  
  Regression and Linear Models in multidimensional spaces become pretty complex, and my comfort level was a little bit off from where I would 
  have wanted it to be. As the week went on and I practiced DOING regression on larger and larger datasets, I got the hang of things, but that initial start
  was tough for a number of us to approach. By midweek, I'd say everyone in the cohort had grasped the concepts, which made pair programming exercises
  better since among in the closest 5 people in the room, at least someone was bound to be able to solve any problem we came across.
     
     
#### Topics Covered:

1. __Numpy & Linear Algebra__ 
  * This was one of the best parts of the week. Partially because I like math, but also because the age-old complaint 
  of, 'But when will we ever do this in real life?' was answered. Math, especially linear algebra, can take quite a
  while to do by hand. Learning the concepts of LA over again and seeing how the Numpy module can perform 
  those computations with lightning speed was a sort of breakthrough in seeing why Machine Learning, if done right, is so cool.  
  
  The algorithms we do in Data Science COULD be done by hand, but some might take days or even months to complete.
  The reason Data Scientists aren't JUST statisticians is because the real value coming from their work 
  comes in knowing HOW things run AND being able to rapidly tune parameters to improve quality.
 
  
2. __Regression (linear and logistic)__  
 ![Make some more lines here...](https://media.giphy.com/media/K82pBft5eET1C/giphy.gif)
 * We learned Linear and Logistic regression modeling, both of which are indispensible in industry. Linear models 
 make predicting continuous data easy with a relatively high success rates. Logistic is just as easy but predicts categories. 
 I'm putting in some practice this weekend learning to plot my findings in a nice, clean way, since even the best models are useless if you can't communicate them. 
 
 
3. __Cross Validation__
* It's smart to validate the models we make - and doing so on unseen 'test' data sets is a great way to go. Cross Validation is on of method of working with 
test and train data that uses resampling to get better estimates of model performance. Mainly used in situations where the goal is prediction, meaning 'What 
would happen for x, y an z?', it greatly alleviates overfitting (getting a fantastic training model that does poorly with any unseen data) and helps get nicely 
tuned hyperparameters (variations in which coefficients are important and which are not). 


Overall, this was another tough week that was super enriching and rewarding. Plus, I like math, which was really really handy. 
 
